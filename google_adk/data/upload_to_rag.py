"""
ê°•ë‚¨ëŒ€í•™êµ ì¡¸ì—…ì´ìˆ˜í•™ì  JSON ë°ì´í„°ë¥¼ Vertex AI RAG ì½”í¼ìŠ¤ì— ì—…ë¡œë“œí•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
    python google_adk/data/upload_to_rag.py
"""

import json
import os
from pathlib import Path
import vertexai
from vertexai.preview import rag
from google.cloud import storage

# ==============================
# ì„¤ì •
# ==============================
# í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ ë””ë ‰í† ë¦¬
SCRIPT_DIR = Path(__file__).parent
DATA_DIR = SCRIPT_DIR
RESULT_DIR = SCRIPT_DIR / "result"  # ë¡œì»¬ ê²°ê³¼ ì €ì¥ í´ë”

# result í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
RESULT_DIR.mkdir(exist_ok=True)

# ì²˜ë¦¬í•  JSON íŒŒì¼ë“¤
JSON_FILES = [
    "2017_2025_í†µí•©_ì¡¸ì—…ì´ìˆ˜í•™ì .json",
    # "2025ì´ìƒ ì…í•™ì ì¡¸ì—…ì´ìˆ˜í•™ì .json",
    # "2021~2024í•™ë…„ë„ ì…í•™ì ì¡¸ì—…ì´ìˆ˜í•™ì .json",
    # "2017~2020í•™ë…„ë„ ì…í•™ì ì¡¸ì—…ì´ìˆ˜í•™ì .json",
]

# GCS ì„¤ì •
GCS_BUCKET_NAME = "kangnam-univ"
GCS_BUCKET_LOCATION = "asia-northeast3"  # ì„œìš¸
GCS_RAG_DATA_PATH = "rag_data/kangnam_univ_graduation_requirements_2017_2025.jsonl"  # GCS ê²½ë¡œ

# ì½”í¼ìŠ¤ ë‚´ íŒŒì¼ëª… (display_name)
CORPUS_FILE_DISPLAY_NAME = "ê°•ë‚¨ëŒ€í•™êµ_ì¡¸ì—…ì´ìˆ˜í•™ì _2017_2025"  # ì½”í¼ìŠ¤ ì•ˆì—ì„œ ë³´ì´ëŠ” ì´ë¦„

# Vertex AI ì„¤ì •
PROJECT_ID = "kangnam-backend"
LOCATION = "us-east4"
CORPUS_ID = "6917529027641081856"
CORPUS_NAME = f"projects/{PROJECT_ID}/locations/{LOCATION}/ragCorpora/{CORPUS_ID}"

# ==============================
# ì´ˆê¸°í™”
# ==============================
print(f"ğŸ”„ ì´ˆê¸°í™” ì¤‘...")
print(f"   í”„ë¡œì íŠ¸: {PROJECT_ID}")
print(f"   Vertex AI ë¦¬ì „: {LOCATION}")
print(f"   GCS ë²„í‚·: gs://{GCS_BUCKET_NAME}")
print(f"   ì½”í¼ìŠ¤ ID: {CORPUS_ID}\n")

# Vertex AI ì´ˆê¸°í™”
vertexai.init(project=PROJECT_ID, location=LOCATION)

# GCS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
storage_client = storage.Client(project=PROJECT_ID)
bucket = storage_client.bucket(GCS_BUCKET_NAME)

# ==============================
# í—¬í¼ í•¨ìˆ˜
# ==============================
def merge_departments(department_data):
    """ê³„ì—´ êµ¬ì¡°ë¥¼ í‰íƒ„í™”í•˜ì—¬ í•™ê³¼/ì „ê³µëª…ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ë³‘í•©"""
    names = []
    for dept in department_data:
        if "í•™ë¶€" in dept:
            names.append(dept["í•™ë¶€"])
        if "í•™ê³¼" in dept:
            names.append(dept["í•™ê³¼"])
        if "ì „ê³µ" in dept:
            names.extend(dept["ì „ê³µ"])
    return ", ".join(names)

def extract_year_range_from_filename(filename):
    """íŒŒì¼ëª…ì—ì„œ í•™ë…„ë„ ë²”ìœ„ ì¶”ì¶œ"""
    if "2017_2025_í†µí•©" in filename:
        return "2017-2025"
    elif "2025ì´ìƒ" in filename:
        return "2025+"
    elif "2021~2024" in filename:
        return "2021-2024"
    elif "2017~2020" in filename:
        return "2017-2020"
    return "unknown"

# ==============================
# JSON ë°ì´í„° ì²˜ë¦¬
# ==============================
all_chunks = []

for json_file in JSON_FILES:
    json_path = DATA_DIR / json_file
    
    if not json_path.exists():
        print(f"âš ï¸  íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {json_file}")
        continue
    
    print(f"ğŸ“‚ ì²˜ë¦¬ ì¤‘: {json_file}")
    
    with open(json_path, "r", encoding="utf-8") as f:
        file_data = json.load(f)
    
    # íŒŒì¼ëª…ì—ì„œ ê¸°ë³¸ year_range ì¶”ì¶œ (fallbackìš©)
    default_year_range = extract_year_range_from_filename(json_file)
    document_title = file_data.get("document_title", "")
    
    # data ë°°ì—´ ê°€ì ¸ì˜¤ê¸°
    colleges_data = file_data.get("data", [])
    
    for college_info in colleges_data:
        college = college_info.get("ëŒ€í•™", "")
        grad_req = college_info.get("ì¡¸ì—…ìš”ê±´", {})
        liberal_arts = college_info.get("êµì–‘ì´ìˆ˜í‘œ", {})
        divisions = college_info.get("ê³„ì—´", [])
        
        # â­ JSON ë‚´ë¶€ì˜ year_rangeë¥¼ ìš°ì„  ì‚¬ìš©, ì—†ìœ¼ë©´ íŒŒì¼ëª…ì—ì„œ ì¶”ì¶œí•œ ê°’ ì‚¬ìš©
        year_range = college_info.get("year_range", default_year_range)
        
        for division in divisions:
            division_name = division.get("ê³„ì—´ëª…", "")
            departments_list = division.get("í•™ë¶€ë°í•™ê³¼", [])
            departments_str = merge_departments(departments_list)
            
            # Chunk 1: ì¡¸ì—…ìš”ê±´
            if grad_req:
                content = f"""
[ì¡¸ì—…ìš”ê±´ ì •ë³´]
ëŒ€í•™: {college}
ê³„ì—´: {division_name}
í•™ê³¼/ì „ê³µ: {departments_str}
í•™ë…„ë„: {year_range}

ì¡¸ì—…ìš”ê±´:
- ê¸°ì´ˆêµì–‘: {grad_req.get('ê¸°ì´ˆêµì–‘', 'N/A')}í•™ì 
- ê³„ì—´êµì–‘: {grad_req.get('ê³„ì—´êµì–‘', 'N/A')}í•™ì 
- ê· í˜•êµì–‘: {grad_req.get('ê· í˜•êµì–‘', 'N/A')}
- ì‹¬í™”ì „ê³µì ì „ê³µí•™ì : {grad_req.get('ì‹¬í™”ì „ê³µì', {}).get('ì „ê³µê¸°ì´ˆ+ì „ê³µì„ íƒ', 'N/A')}í•™ì 
- ë‹¤ì „ê³µì ì „ê³µí•™ì : {grad_req.get('ë‹¤ì „ê³µì', {}).get('ì „ê³µê¸°ì´ˆ+ì „ê³µì„ íƒ', 'N/A')}í•™ì 
- ìµœì†Œì¡¸ì—…í•™ì : {grad_req.get('ìµœì†Œì¡¸ì—…í•™ì ', 'N/A')}í•™ì 
""".strip()
                
                all_chunks.append({
                    "content": content,
                    "metadata": {
                        "college": college,
                        "division": division_name,
                        "department": departments_str,
                        "year_range": year_range,
                        "category": "ì¡¸ì—…ìš”ê±´",
                        "language": "ko",
                        "source_file": json_file
                    }
                })
            
            # Chunk 2: êµì–‘ì´ìˆ˜í‘œ
            if liberal_arts:
                # êµì–‘ì´ìˆ˜í‘œë¥¼ í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…
                liberal_text_parts = [
                    f"[êµì–‘ì´ìˆ˜í‘œ]",
                    f"ëŒ€í•™: {college}",
                    f"ê³„ì—´: {division_name}",
                    f"í•™ê³¼/ì „ê³µ: {departments_str}",
                    f"í•™ë…„ë„: {year_range}",
                    "",
                    "êµì–‘ ê³¼ëª©:"
                ]
                
                for category, subjects in liberal_arts.items():
                    if isinstance(subjects, list):
                        liberal_text_parts.append(f"\n{category}:")
                        for subject in subjects:
                            liberal_text_parts.append(f"  - {subject}")
                    else:
                        liberal_text_parts.append(f"{category}: {subjects}")
                
                content = "\n".join(liberal_text_parts)
                
                all_chunks.append({
                    "content": content,
                    "metadata": {
                        "college": college,
                        "division": division_name,
                        "department": departments_str,
                        "year_range": year_range,
                        "category": "êµì–‘ì´ìˆ˜í‘œ",
                        "language": "ko",
                        "source_file": json_file
                    }
                })
    
    print(f"   âœ… {len([c for c in all_chunks if c['metadata']['source_file'] == json_file])}ê°œ chunk ìƒì„±")

print(f"\nğŸ“Š ì´ {len(all_chunks)}ê°œì˜ chunk ìƒì„± ì™„ë£Œ\n")

# ==============================
# ë¡œì»¬ result í´ë”ì— JSONL ì €ì¥ (í™•ì¸ìš©)
# ==============================
print(f"ğŸ’¾ ë¡œì»¬ result í´ë”ì— ì €ì¥ ì¤‘...")

# JSONL ë¬¸ìì—´ ìƒì„±
jsonl_content = "\n".join([
    json.dumps(chunk, ensure_ascii=False) 
    for chunk in all_chunks
])

# ë¡œì»¬ íŒŒì¼ë¡œ ì €ì¥
local_jsonl_path = RESULT_DIR / "kangnam_univ_graduation_requirements.jsonl"
with open(local_jsonl_path, "w", encoding="utf-8") as f:
    f.write(jsonl_content)

print(f"   âœ… ë¡œì»¬ ì €ì¥ ì™„ë£Œ!")
print(f"   ğŸ“ ê²½ë¡œ: {local_jsonl_path}")
print(f"   ğŸ“¦ í¬ê¸°: {len(jsonl_content.encode('utf-8')) / 1024:.2f} KB")
print(f"\n   ğŸ’¡ ì—…ë¡œë“œ ì „ì— íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”: {local_jsonl_path}\n")

# ì‚¬ìš©ì í™•ì¸
confirm = input("ğŸš€ GCSì— ì—…ë¡œë“œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (yes/no): ").strip().lower()
if confirm not in ['yes', 'y']:
    print("âŒ ì—…ë¡œë“œê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"   ë¡œì»¬ íŒŒì¼: {local_jsonl_path}")
    exit(0)

# ==============================
# GCSì— JSONL ì—…ë¡œë“œ
# ==============================
print(f"\nâ˜ï¸  GCSì— ì—…ë¡œë“œ ì¤‘...")
print(f"   ë²„í‚·: gs://{GCS_BUCKET_NAME}")
print(f"   ê²½ë¡œ: {GCS_RAG_DATA_PATH}")

# GCSì— ì—…ë¡œë“œ
try:
    blob = bucket.blob(GCS_RAG_DATA_PATH)
    blob.upload_from_string(
        jsonl_content,
        content_type="application/jsonl"
    )
    
    gcs_uri = f"gs://{GCS_BUCKET_NAME}/{GCS_RAG_DATA_PATH}"
    print(f"   âœ… GCS ì—…ë¡œë“œ ì™„ë£Œ!")
    print(f"   ğŸ“ URI: {gcs_uri}")
    print(f"   ğŸ“¦ í¬ê¸°: {len(jsonl_content.encode('utf-8')) / 1024:.2f} KB\n")
    
except Exception as e:
    print(f"\nâŒ GCS ì—…ë¡œë“œ ì‹¤íŒ¨:")
    print(f"   {str(e)}")
    print(f"\nğŸ’¡ í™•ì¸ì‚¬í•­:")
    print(f"   1. ë²„í‚· ì¡´ì¬ ì—¬ë¶€: gs://{GCS_BUCKET_NAME}")
    print(f"   2. ê¶Œí•œ: Storage Object Admin ì—­í• ")
    print(f"   3. ì¸ì¦: gcloud auth application-default login")
    exit(1)

# ==============================
# Vertex AI RAG ì½”í¼ìŠ¤ë¡œ Import
# ==============================
print(f"ğŸš€ Vertex AI RAG ì½”í¼ìŠ¤ì— Import ì¤‘...")
print(f"   ì½”í¼ìŠ¤: {CORPUS_NAME}")
print(f"   ì†ŒìŠ¤: {gcs_uri}")

try:
    # RagFile ì„¤ì •ìœ¼ë¡œ display_name ì§€ì •
    operation = rag.import_files(
        corpus_name=CORPUS_NAME,
        paths=[gcs_uri],
        chunk_size=800,
        chunk_overlap=100,
    )
    
    print(f"   â³ Import ë° ì„ë² ë”© ìƒì„± ì¤‘...")
    print(f"   ğŸ“ ì½”í¼ìŠ¤ ë‚´ í‘œì‹œëª…: {CORPUS_FILE_DISPLAY_NAME}")
    
    try:
        result = operation.result()
        print(f"   âœ… Import ì™„ë£Œ í™•ì¸ë¨!")
    except Exception as result_error:
        print(f"   âš ï¸  ì™„ë£Œ í™•ì¸ ì‹¤íŒ¨ (ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬ ì¤‘ì¼ ìˆ˜ ìˆìŒ)")
        print(f"   ì—ëŸ¬: {str(result_error)}")
    
    print(f"\nâœ… Import ìš”ì²­ ì™„ë£Œ!")
    print(f"   ğŸ“„ ì´ {len(all_chunks)}ê°œ chunk")
    print(f"   ğŸ“ ë¡œì»¬ íŒŒì¼: {local_jsonl_path}")
    print(f"   â˜ï¸  GCS íŒŒì¼: {gcs_uri}")
    print(f"   ğŸ” 1-5ë¶„ í›„ ì½”í¼ìŠ¤ì—ì„œ ê²€ìƒ‰ ê°€ëŠ¥í•©ë‹ˆë‹¤!")
    
except Exception as e:
    print(f"\nâŒ Vertex AI Import ì‹¤íŒ¨:")
    print(f"   {str(e)}")
    print(f"\nğŸ’¡ í™•ì¸ì‚¬í•­:")
    print(f"   1. ì¸ì¦: gcloud auth application-default login")
    print(f"   2. ê¶Œí•œ: Vertex AI User ì—­í• ")
    print(f"   3. API í™œì„±í™”: Vertex AI API")
    print(f"   4. ì½”í¼ìŠ¤ ID: {CORPUS_ID}")
    print(f"   5. GCS íŒŒì¼ ì ‘ê·¼ ê¶Œí•œ")
    exit(1)

